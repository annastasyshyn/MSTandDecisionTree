{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Команда 20\n",
    "* Стасишин Анна\n",
    "* Слаблюк Назар"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ми вирішили обрати датасет про рак грудей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \n",
    "    def __init__(self,X,y,gini,predicted_class=None):\n",
    "        self.X=X\n",
    "        self.y=y\n",
    "        self.gini=gini\n",
    "        self.feature_index=0\n",
    "        self.threshold=0\n",
    "        self.left=None\n",
    "        self.right=None\n",
    "        self.predicted_class=predicted_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Як працює Tree Classiffier\n",
    "### Gini\n",
    "#### В основі нашої моделі лежить функція активації, або ж cost function - Gini, яка обраховується за формулою\n",
    "#### $G = 1 - \\sum_{k=1}^{n}p_{k}^2$ \n",
    "#### Чим ближче Gini до 0, тим є чистішим наш розподіл.\n",
    "### Data split\n",
    "#### Модель перебирає всі можливі варіанти розподілу класів та знаходить найкращий варіант з найменшим Gini. Повертає індекс цього розподілу та межу.  \n",
    "### Build Tree\n",
    "#### Рекурсивно будує дерево. Кожній вершині додає правого чи лівого сина. Якщо у вершини немає дітей - це листок. \n",
    "### Fit\n",
    "#### 'Обгортка' для нашої моделі.\n",
    "### Predict\n",
    "#### Проходить по кожній вершині, допоки в неї є дитина. Якщо в неї нема дітей - обчислює передбачуваний клас.\n",
    "### Evaluate\n",
    "##### Обраховує те, наскільки точно наша модель передбачила класи.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier:\n",
    "\n",
    "    def __init__(self, max_depth):\n",
    "        self.max_depth=max_depth\n",
    "\n",
    "    @staticmethod\n",
    "    def gini(classes):\n",
    "        \"\"\"\n",
    "        A Gini score gives an idea of how good a split is by how mixed the\n",
    "        classes are in the two groups created by the split.\n",
    "        \n",
    "        A perfect separation results in a Gini score of 0,\n",
    "        whereas the worst case split that results in 50/50\n",
    "        classes in each group result in a Gini score of 0.5\n",
    "        (for a 2 class problem).\n",
    "        \"\"\"\n",
    "        num=sum(classes)\n",
    "        return 1-sum((i/num)**2 for i in classes)\n",
    "\n",
    "    def split_data(self,X,y):\n",
    "        \"\"\"\n",
    "        test all the possible splits in O(N*F) where N in number of samples\n",
    "        and F is number of features\n",
    "        return index and threshold value\n",
    "        \"\"\"\n",
    "        m=y.size\n",
    "        if m<=1:\n",
    "            return None, None\n",
    "        num_parent=[np.sum(y==c) for c in range(self.n_classes)]\n",
    "\n",
    "        best_gini=1-sum((n/m)**2 for n in num_parent)\n",
    "        best_index,best_threshold=None,None\n",
    "        for index in range(self.n_features):\n",
    "            thresholds,classes=zip(*sorted(zip(X[:, index],y)))\n",
    "            n_left=[0 for _ in range(self.n_classes)]\n",
    "            n_right=num_parent.copy()\n",
    "            for i in range(1,m):\n",
    "                c=classes[i-1]\n",
    "                n_left[c]+=1\n",
    "                n_right[c]-=1\n",
    "                gini_left=self.gini(n_left)\n",
    "                gini_right=self.gini(n_right)\n",
    "                gini=(i*gini_left+(m-i)*gini_right)/m\n",
    "                if thresholds[i]==thresholds[i-1]:\n",
    "                    continue\n",
    "                if gini<best_gini:\n",
    "                    best_gini=gini\n",
    "                    best_index=index\n",
    "                    best_threshold=(thresholds[i]+thresholds[i-1])/2\n",
    "        return best_index,best_threshold\n",
    "\n",
    "    def build_tree(self,X,y,depth = 0):\n",
    "        \"\"\"\n",
    "        create a root node\n",
    "        recursively split until max depth is not exeeced\n",
    "        \"\"\"\n",
    "        num_samples_per_class=[np.sum(y == i) for i in range(self.n_classes)]\n",
    "        predicted_class = np.argmax(num_samples_per_class)\n",
    "        node=Node(X,y,None,predicted_class)\n",
    "        if depth<self.max_depth:\n",
    "            index,threshold=self.split_data(X,y)\n",
    "            if index is not None:\n",
    "                node.gini=self.gini(y)\n",
    "                indices_left=X[:,index]<threshold\n",
    "                X_left,y_left=X[indices_left],y[indices_left]\n",
    "                X_right,y_right=X[~indices_left],y[~indices_left]\n",
    "                node.feature_index=index\n",
    "                node.threshold=threshold\n",
    "                node.left=self.build_tree(X_left,y_left,depth+1)\n",
    "                node.right=self.build_tree(X_right,y_right,depth+1)\n",
    "        return node\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        basically wrapper for build tree / train\n",
    "        \"\"\"\n",
    "        self.n_classes=len(set(y))\n",
    "        self.n_features=X.shape[1]\n",
    "        self.tree=self.build_tree(X,y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        traverse the tree while there is a child\n",
    "        and return the predicted class for it, \n",
    "        note that X_test can be a single sample or a batch\n",
    "        \"\"\"\n",
    "        predictions=[]\n",
    "        for inputs in X:\n",
    "            node=self.tree\n",
    "            while node.left:\n",
    "                if inputs[node.feature_index]<node.threshold:\n",
    "                    node=node.left\n",
    "                else:\n",
    "                    node=node.right\n",
    "            predictions.append(node.predicted_class)\n",
    "        return predictions\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        return accuracy\n",
    "        \"\"\"\n",
    "        predictions=self.predict(X_test)\n",
    "        return sum(predictions==y_test)/len(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9210526315789473"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer=load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size= 0.20)\n",
    "clf=MyDecisionTreeClassifier(10)\n",
    "clf.fit(X,y)\n",
    "clf.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Висновок\n",
    "#### Під час виконання лабораторної роботи, із застосування такого принципу дискретної математики, як дерево рішень, ми створили власну імплементацію Decision Tree Classifier, який є одним із підходів у контрольованому машинному навчанні. Загальна точність вийшла в проміжку (0.9;1), що свідчить про коректність роботи нашої імплементації."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "1bcda7f0f500a519819f04aa78fd9b16c83c6837b33648154c3ad4c5c3248eeb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
